# -*- coding: utf-8 -*-
"""Resnet dropout1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ED7s1USeoYLNBzt62xhar23VPBxvNIEt
"""

import pickle

#cd /content/drive/MyDrive/Resulttrain8000

#from google.colab import drive
#drive.mount('/content/drive')

import os
from PIL import Image
import numpy as np
import keras
import os
import cv2
from matplotlib import pyplot as plt
from keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.applications.xception import Xception
from keras.applications.mobilenet_v2 import MobileNetV2
from keras.applications.inception_v3 import InceptionV3
from keras.applications.densenet import DenseNet121
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np
from keras.applications.vgg16 import decode_predictions
import tensorflow as tf
from tensorflow.python.keras import layers
from tensorflow.python.keras import models
import random

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

#cd /content/drive/MyDrive/Resulttrain8000

with open('Xtrain.pkl','rb') as f2:
    X1=pickle.load(f2)

type(X1)

with open('Xnontrain.pkl','rb') as f2:
    X2=pickle.load(f2)

with open('XModetrain.pkl','rb') as f2:
    X3=pickle.load(f2)

with open('Xvmildtrain.pkl','rb') as f2:
    X4=pickle.load(f2)

X=X1+X2+X3+X4

print(np.shape(X))

#cd /content/drive/MyDrive/Resultvmild

with open('ytrain.pkl','rb') as f2:
    y1=pickle.load(f2)

with open('ynontrain.pkl','rb') as f2:
    y2=pickle.load(f2)

with open('ymodetrain.pkl','rb') as f2:
    y3=pickle.load(f2)

with open('yvmildtrain.pkl','rb') as f2:
    y4=pickle.load(f2)

type(y1)

print(y1)

y=y1+y2+y3+y4

print(np.shape(y))
print(np.shape(X))

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y = encoder.fit_transform(y)
print(y)

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel

clf = ExtraTreesClassifier(n_estimators=50)
clf = clf.fit(X, y)
model = SelectFromModel(clf, prefit=True)
X = model.transform(X)

print(np.shape(X))
print(np.shape(y))

from sklearn.model_selection import train_test_split
      
#X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y),  test_size=0.3, random_state=42)

# set aside 20% of train and test data for evaluation
X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y),
    test_size=0.2, shuffle = True, random_state = 8)

# Use the same function above for the validation set
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, 
    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2
#X_train = X_train.reshape(-1, 224, 224, 1)
#X_test = X_test.reshape(-1, 224, 224, 1)

print("X_train shape: {}".format(X_train.shape))
print("y_train shape: {}".format(y_train.shape))
print("X_test shape: {}".format(X_test.shape))
print("y_test shape: {}".format(y_test.shape))
print("X_val shape: {}".format(X_val.shape))
print("y_val shape: {}".format(y_val.shape))

random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

from keras.layers import Dropout

dnnModel=models.Sequential()
dnnModel.add(layers.Dense(10000,activation="relu",input_shape=(np.shape(X_train)[1],)))

dnnModel.add(layers.Dense(5000,activation="relu"))

dnnModel.add(layers.Dense(2000,activation="relu"))
dnnModel.add(layers.Dense(500,activation="relu"))
dnnModel.add(layers.Dense(300,activation="relu"))
dnnModel.add(Dropout(0.3))
dnnModel.add(layers.Dense(200,activation="relu"))
dnnModel.add(layers.Dense(120,activation="relu"))
dnnModel.add(layers.Dense(30,activation="relu"))
dnnModel.add(layers.Dense(30,activation="relu"))
dnnModel.add(layers.Dense(4,activation="softmax"))
dnnModel.summary()

opt=tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name="Adam"
)

dnnModel.compile(optimizer="adam",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

history=dnnModel.fit(X_train,y_train,epochs=50,batch_size=32,validation_data=(X_val,y_val))

pred=np.argmax(dnnModel.predict(X_val), axis=-1)

import seaborn as sns
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
result = confusion_matrix(y_val.ravel(), pred)
print(result)
sns.heatmap(result,cmap='Greens', annot=True, xticklabels = ["mild", "moder","non","very"],yticklabels = ["mild", "moder","non","very"])
ac = accuracy_score(y_val,pred)
#print(result)
print(ac)
print(classification_report(y_val,pred))


from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
result = confusion_matrix(y_val.ravel(), pred)
print(result)
sns.heatmap(result,cmap='Greens', annot=True, xticklabels = ["mild", "moder","non","very"],yticklabels = ["mild", "moder","non","very"])
ac = accuracy_score(y_val,pred)
#print(result)
print(ac)
print(classification_report(y_val,pred))

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train'],loc='upper left')
plt.show()

from sklearn.metrics import roc_curve

# roc curve for model
fpr1, tpr1, thresh1 = roc_curve(y_val, pred, pos_label=1)


# roc curve for tpr = fpr 
random_probs = [0 for i in range(len(y_val))]
p_fpr, p_tpr, _ = roc_curve(y_val, random_probs, pos_label=1)

# matplotlib
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='DNN-Model')
plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')
# title
plt.title('ROC curve')
# x label
plt.xlabel('False Positive Rate')
# y label
plt.ylabel('True Positive rate')

plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train'],loc='upper left')
plt.show()
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'],loc='upper left')         #representation box in the plot
plt.show()
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train_loss','val_loss'],loc='upper left')         #representation box in the plot
plt.show()